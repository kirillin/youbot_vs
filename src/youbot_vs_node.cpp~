/**
 *
 *  author: kirillin
 *  created: 20.05.19.
**/
#include <ros/ros.h>
#include <tf/transform_broadcaster.h>

#include <fstream>
#include <visp3/core/vpImage.h>
#include <visp3/sensor/vpRealSense2.h>
#include <visp3/gui/vpDisplayX.h>

#include <visp3/vision/vpPose.h>
#include <visp3/core/vpDisplay.h>
#include <visp3/core/vpPixelMeterConversion.h>

#include <visp3/imgproc/vpImgproc.h>
#include <visp3/core/vpImageFilter.h>

#include <visp3/blob/vpDot2.h>

#include <visp3/visual_features/vpFeaturePoint.h>
#include <visp3/visual_features/vpFeatureBuilder.h>
#include <visp3/vs/vpServo.h>

#include <visp3/core/vpXmlParserCamera.h>
#include <visp3/io/vpImageIo.h>

#include <boost/units/io.hpp>
#include <boost/units/systems/si/angular_velocity.hpp>
#include <boost/units/systems/si/velocity.hpp>
#include <boost/units/systems/angle/degrees.hpp>
#include <boost/units/conversion.hpp>

#include <sensor_msgs/JointState.h>
#include <brics_actuator/JointVelocities.h>
#include <brics_actuator/JointPositions.h>

#include <youbot_arm_kinematics/kinematics.h>


class YoubotVS {

    int RATE = 30;
    int Np = 4;

    double opt_square_width = 0.06;
    double L = opt_square_width / 2.;
    double distance_same_blob = 10.; // 2 blobs are declared same if their distance is less than this value

    ros::NodeHandle nh;
    ros::Publisher arm_velocity_pub;
    ros::Subscriber arm_js_sub;

    Kinematics ks;

    Matrix<double, 1, 5> q_state;
    Vector6d v_des;


public:
    YoubotVS() {
        ROS_INFO("Youbot VS initialized.");

        arm_velocity_pub = nh.advertise<brics_actuator::JointVelocities>("arm_1/arm_controller/velocity_command", 1);
        arm_js_sub = nh.subscribe("joint_states", 10, &YoubotVS::js_callback, this);

        VectorNd v1; v1 << 0.033, 0.155, 0.135, 0.0, 0.0;
        VectorNd v2; v2 << M_PI/2.0, 0.0, 0.0, M_PI/2.0, 0.0;
        VectorNd v3; v3 << 0.147, 0.0, 0.0, 0.0, 0.218;
        VectorNd v4; v4 << M_PI*169.0/180.0, M_PI*65.0/180.0+M_PI/2, -M_PI*146.0/180.0, M_PI*102.5/180.0+M_PI/2, M_PI*167.5/180.0;
        Kinematics ks_(v1, v2, v3, v4);
        ks = ks_;

        q_state << 0,0,0,0,0;
        v_des << 0,0,0, 0,0,0;
    }

    ~YoubotVS() {
        arm_velocity_pub.shutdown();
        arm_js_sub.shutdown();
    }

    void computePose(std::vector<vpPoint> &point, const std::vector<vpImagePoint> &ip,
                     const vpCameraParameters &cam, bool init, vpHomogeneousMatrix &cMo)
    {
        vpPose pose;
        double x = 0, y = 0;
        for (unsigned int i = 0; i < point.size(); i++) {
            vpPixelMeterConversion::convertPoint(cam, ip[i], x, y);
            point[i].set_x(x);
            point[i].set_y(y);
            pose.addPoint(point[i]);
        }

        if (init == true) {
            vpHomogeneousMatrix cMo_dem;
            vpHomogeneousMatrix cMo_lag;
            pose.computePose(vpPose::DEMENTHON, cMo_dem);
            pose.computePose(vpPose::LAGRANGE, cMo_lag);
            double residual_dem = pose.computeResidual(cMo_dem);
            double residual_lag = pose.computeResidual(cMo_lag);
            if (residual_dem < residual_lag)
                cMo = cMo_dem;
            else
                cMo = cMo_lag;
        }
        pose.computePose(vpPose::VIRTUAL_VS, cMo);
    }

    void js_callback(const sensor_msgs::JointState &msg) {

        brics_actuator::JointVelocities arm_velocities;
        vector<brics_actuator::JointValue> point;

        /* feedback measurements'q' */
        Matrix<double, 1, 5> q;
        for (int i = 0; i < 5; i++) {
            q(i) = msg.position[i];
        }
        q_state = q;

        Matrix<double, 6, 5> J;
        ks.get_jacobn(q, J);

        Matrix<double, 5, 6> pinvJ;
        ks.pinv(J, pinvJ);

        VectorNd dq = pinvJ * v_des;

        if (dq.sum() < 5) {
            std::stringstream joint_name;
            point.resize(5);
            for (int i = 0; i < 5 /*+2*/; i++) {
                if (i < 5) { /* link's joints */
                    joint_name.str("");
                    joint_name << "arm_joint_" << (i + 1);

                    point[i].joint_uri = joint_name.str();
                    point[i].value = dq(i);
                    point[i].unit = boost::units::to_string(boost::units::si::radian_per_second);
                } else {  /* gripper joints */
                    if (i == 5) {
                        point[i].joint_uri = "gripper_finger_joint_l";
                    } else {
                        point[i].joint_uri = "gripper_finger_joint_r";
                    }
                    point[i].value = 0;
                    point[i].unit = boost::units::to_string(boost::units::si::meter_per_second);
                }
            };
            arm_velocities.velocities = point;
            arm_velocity_pub.publish(arm_velocities);
        } else {
            clog << "STOP! Jacobian is close to singularity! Velocities sre very big!" << endl;
        }
    }

    void work() {
        try {
            vpImage<unsigned char> I;

            /* CAMERA SETUP */
            vpRealSense2 g;

            rs2::config config;
            config.disable_stream(RS2_STREAM_DEPTH);
            config.disable_stream(RS2_STREAM_INFRARED);
            config.enable_stream(RS2_STREAM_COLOR, 640, 480, RS2_FORMAT_RGBA8, 30);
            g.open(config);

            g.acquire(I);

            vpCameraParameters cam(840, 840, I.getWidth() / 2, I.getHeight() / 2);
            cam = g.getCameraParameters(RS2_STREAM_COLOR, vpCameraParameters::perspectiveProjWithoutDistortion);

            std::cout << cam << std::endl;

            vpImagePoint germ[Np];
            vpDot2 blob[Np];

            for(int i = 0; i < Np; i++) {
                blob[i].setGraphics(true);
                blob[i].setGraphicsThickness(1);
            }
            
            /*  --> x,u
                |   0   1
                |   3   2
               y,v
            */
            std::vector<vpPoint> point_d;
            point_d.push_back(vpPoint(-L, -L, 0));
            point_d.push_back(vpPoint(-L,  L, 0));
            point_d.push_back(vpPoint( L,  L, 0));
            point_d.push_back(vpPoint( L, -L, 0));


            vpDisplayX d;
            d.init(I, 20, 40, "Original");

            std::vector<vpImagePoint> ip;
            std::vector<vpImagePoint> ipd;


            /*
                --> w
                |   lt  rt
                |   lb  rb
                h

            */
            double w, h; h = I.getWidth()/2; w = I.getHeight()/2;
            ipd.push_back(vpImagePoint(w-100, h-100)); // left top
            ipd.push_back(vpImagePoint(w+100, h-100)); // right top
            ipd.push_back(vpImagePoint(w+100, h+100)); // right bottom
            ipd.push_back(vpImagePoint(w-100, h+100)); // left bottom

            vpHomogeneousMatrix cMo, cdMo, wMc, wMo;
            computePose(point_d, ipd, cam, true, cdMo);

            vpServo task;
            task.setServo(vpServo::EYEINHAND_CAMERA);
            task.setInteractionMatrixType(vpServo::CURRENT);
            task.setLambda(0.2);

            vpFeaturePoint p[4], pd[4];

            bool init_cv = true;   // initialize tracking and pose computation
            bool learn = true;
            bool isTrackingLost = false;
            bool send_velocities = false;
            bool final_quit = false;

            ros::Rate R(RATE);
            int k = 0;
            double t;
            static double t_init_servo = vpTime::measureTimeMs();

            while(nh.ok() && !final_quit) {
                double t_start = vpTime::measureTimeMs();
                t = vpTime::measureTimeMs();

                try {
                    g.acquire(I);
                    vpDisplay::display(I);

                    std::stringstream ss;
                    ss << (send_velocities ? "STOP the robot" : "SERVO the robot");
                    vpDisplay::displayText(I, 20, 20, ss.str(), vpColor::green);

                    //vpColVector v_c(6);
                    Matrix<double, 6, 1> v_c;
                    Matrix<double, 6, 1> v_e;
    
                    if (!learn) {
                        vpDisplay::displayText(I, vpImagePoint(80, 20), "Tracking is ok!", vpColor::green);
                        try {

                            Matrix<double, 8, 6> L = Matrix<double, 8, 6>::Zero();
                            std::vector<vpImagePoint> ip(Np);

                            for(int i = 0; i < Np; i++) {
                                std::stringstream ss;
                                ss << "p" << i;
                                vpDisplay::displayText(I, blob[i].getCog(), ss.str(), vpColor::white);

                                blob[i].track(I);
                                ip[i] = blob[i].getCog();

                                double Z = 0.5; // can be estimated from square dims
                                double u = ip[i].get_u();
                                double v = ip[i].get_v();

                                Matrix<double, 2, 6> Lx;
                                Lx << -1/Z, 0, u/Z, u * v, -(1 + u * u), v,
                                        0, -1/Z, v/Z, 1 + v * v, -u * v, -u;

                                // Copy one point-matrix to full image-jacobian
                                for (int j = 0; j < 6; j++) {
                                    for (int k = 0; k < 2; k++) {
                                        L(k + 2 * i, j) = Lx(k, j);
                                    }
                                }
//                                std::cout << L << std::endl << std::endl;
                                vpDisplay::displayLine(I, ipd[i], ip[i], vpColor::red, 1);
                            }

                            std::cout << "L = \n" << L << std::endl;
                            
                            // Try to pseudo-inverse
                            double alpha0 = 0.0001;
                            double w0 = 0.00001;
                            double w = 0, alpha = 0;

                            double detL = (L * L.transpose()).determinant();
                            if (detL < 1.0e-10) {
                                w = 1.0e-5;
                            } else {
                                w = sqrt(detL);
                            }

                            if (w >= w0) {
                                alpha = 0;
                            } else {
                                alpha = alpha0 * (1.0 - w / w0) * (1 - w / w0);
                            }
                            // 6x8 = 6x8 * (8x6 * 6x8)
                            Matrix<double, 6, 8> pinvL = L.transpose() * (L * L.transpose() - alpha * MatrixXd::Identity(8,8)).inverse();

                            std::cout << "pinvL = \n" << pinvL << std::endl;

                            // Compute error
                            Matrix<double, 8, 1> error = Matrix<double, 8, 1>::Zero();
                            for (int i = 0; i < Np; i++) {
                                for (int j = 0; j < 2; j++) {
                                    // error in image space for one point
                                    double ex = ip[i].get_u() - ipd[i].get_u();
                                    double ey = ip[i].get_v() - ipd[i].get_v();
                                    error(j + 2 * i) = ex;
                                    error(j + 2 * i) = ey;
                                }
                            }

                            std::cout << "error = \n" << error << std::endl;
                            
                            // Compute velocities
                            // 6x1 = 6x8 * 8x1
                            v_c = pinvL * error;

                            std::cout << "v_c = \n"<< v_c << std::endl;

                            Matrix<double, 3, 3> zeros;
                            zeros << 0,0,0,
                                     0,0,0,
                                     0,0,0;

                            Matrix<double, 3, 3> eRc;
                            // roatate to pi/2 around Z-axis
                            eRc << 0, -1, 0,
                                   1,  0, 0,
                                   0,  0, 1;


                            MatrixXd eVc(6, 6);
                            
                                  
                            eVc = eRc, zeros, zeros, eRc;
                            
                            std::cout << "eVc = \n" << eVc << std::endl;
                                  
                            v_e = eVc * v_c;
                            
                            std::cout << "v_e = \n"<< v_e << std::endl;


                            vpDisplay::displayArrow(I, vpImagePoint(w, h), vpImagePoint(w + v_c[0]*1000, h), vpColor::red);
                            vpDisplay::displayArrow(I, vpImagePoint(w, h), vpImagePoint(w, h + v_c[1]*1000), vpColor::green);

                            vpDisplay::displayArrow(I, vpImagePoint(w, h), vpImagePoint(w + v_c[0]*1000, h + v_c[1]*1000), vpColor::white);


                            computePose(point_d, ip, cam, init_cv, cMo);
                            if (init_cv) init_cv = false;
//                            vpDisplay::displayFrame(I, cdMo, cam, opt_square_width, vpColor::none, 1);
//                            vpDisplay::displayFrame(I, cMo, cam, opt_square_width, vpColor::none, 2);
//                            vpColVector v_c = task.computeControlLaw();

                            if (!send_velocities) {
                                for (int j = 0; j < 6; j++) {
                                    v_e(j) = 0;
                                }
                            }

                            for(int j = 0; j < 6; j++) {
                                if (j == 2) {
                                    v_e(j) = 0;
                                }
                                v_des(j) = v_e(j);
                            }


                        } catch(...) {
                            std::cout << "Computer vision failure.\n";
//                                isTrackingLost = true;
                        }
                    } else {
                        if (vpDisplay::getClick(I, germ[k], false)) {
                            blob[k].initTracking(I, germ[k]);

                            //vpFeatureBuilder::create(pd[k], point_d[k]);
                            vpFeatureBuilder::create(pd[k], cam, ipd[k]);
                            vpFeatureBuilder::create(p[k], cam, blob[k].getCog());
                            p[k].set_Z(0.5);

                            task.addFeature(p[k], pd[k]);

                            k++;
                        }
                        if (k == Np) {
                            learn = false;
                            k = 0;
                        }
                    }

                    vpDisplay::flush(I);

                    ss.str("");
                    ss << "Loop time: " << vpTime::measureTimeMs() - t_start << " ms";
                    vpDisplay::displayText(I, 40, 20, ss.str(), vpColor::white);
                    vpDisplay::flush(I);

                    vpMouseButton::vpMouseButtonType button;
                    if (vpDisplay::getClick(I, button, false)) {
                        switch (button) {
                            case vpMouseButton::button1:
                                send_velocities = !send_velocities;
                                std::cout << "Send velocities mode changed." << std::endl;
                                break;

                            case vpMouseButton::button2:
                                init_cv = true;   // initialize tracking and pose computation
                                learn = true;
                                send_velocities = false;
                                std::cout << "Reseted." << std::endl;
                                break;

                            case vpMouseButton::button3:
                                for(int j = 0; j < 6; j++) {
                                    v_e(j) = 0;
                                }
                                final_quit = true;
                                std::cout << "Quited." << std::endl;
                                break;

                            default:
                                break;
                        }
                    }

                } catch (...) {
                    isTrackingLost = true;
                    std::cout << "Tracking lost. Finding blobs..    .\r";
                }

                ros::spinOnce();
                R.sleep();
            }
            task.kill();
        } catch (const vpException &e) {
            std::stringstream ss;
            ss << "vpException: " << e;
            std::cout << ss.str() << std::endl;
        }
    }



    void workCalibration() {

        try {
            vpImage<unsigned char> I;

            vpRealSense2 g;
            rs2::config config;
            config.disable_stream(RS2_STREAM_DEPTH);
            config.disable_stream(RS2_STREAM_INFRARED);
            config.enable_stream(RS2_STREAM_COLOR, 640, 480, RS2_FORMAT_RGBA8, 30);
            g.open(config);
            g.acquire(I);

            unsigned int width = I.getWidth();
            unsigned int height = I.getHeight();

            std::cout << "Image size: " << width << " x " << height << std::endl;
            // Save intrinsics
            vpCameraParameters cam;
            vpXmlParserCamera xml_camera;
            cam = g.getCameraParameters(RS2_STREAM_COLOR, vpCameraParameters::perspectiveProjWithDistortion);
            xml_camera.save(cam, "camera.xml", "Camera", width, height);

            vpDisplayX dc(I, 10, 10, "Color image");

            ros::Rate R(RATE);

            bool end = false;
            unsigned cpt = 0;
            while (nh.ok() && !end) {
                g.acquire(I);

                vpDisplay::display(I);

                vpDisplay::displayText(I, 15, 15, "Left click to acquire data", vpColor::red);
                vpDisplay::displayText(I, 30, 15, "Right click to quit", vpColor::red);
                vpMouseButton::vpMouseButtonType button;
                if (vpDisplay::getClick(I, button, false)) {
                    if (button == vpMouseButton::button1) {
                        cpt++;

                        Vector6d s = ks.forward(q_state, 0, 5);
                        vpPoseVector fPe(s(0), s(1), s(2), s(3), s(4), s(5));
                        std::cout << q_state << std::endl;
                        std::cout << s.transpose() << std::endl;

                        std::stringstream ss_img, ss_pos;

                        ss_img << "image-" << cpt << ".png";
                        ss_pos << "pose_fPe_" << cpt << ".yaml";
                        std::cout << "Save: " << ss_img.str() << " and " << ss_pos.str() << std::endl;
                        vpImageIo::write(I, ss_img.str());
                        fPe.saveYAML(ss_pos.str(), fPe);
                    } else if (button == vpMouseButton::button3) {
                        end = true;
                    }
                }
                vpDisplay::flush(I);

                ros::spinOnce();
                R.sleep();
            }
        } catch (const vpException &e) {
            std::cerr << "RealSense error " << e.what() << std::endl;
        } catch (const std::exception &e) {
            std::cerr << e.what() << std::endl;
        }
    }
};

int main(int argc, char** argv) {
    ros::init(argc, argv, "youbot_vs_node");

    YoubotVS ybvs;
    ybvs.work();
    //ybvs.workCalibration();

    return 0;
}
